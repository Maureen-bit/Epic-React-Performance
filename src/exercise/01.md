# Code splitting

## üìù Your Notes

We use `<React.Lazy />` component when we need to render a dynamic import as a regular component. `<React.Lazy />` takes a function that must call a dynamic import(). This must return a Promise which resolves to a module with a default export containing a React component. We use `<React.Suspense />` component to show some fallback content (such as a loading indicator) while we‚Äôre waiting for the lazy component to load.

When we load a component with `<React.Lazy />` and `<React.Suspense />` Instead of loading all the components at the same time, we can see that the component files (chunk files) are called once we trigger an action from the front-end interface. The action could be a click, a check box, a query, etc. These chunk files are calling through lazy loading and we can review them in the Network tab when we explore the dev tools.

For this particular case (globe exercise), we found that once the 'show globe' is checked, the http://localhost:3000/static/js/vendors-node_modules_d3-geo_src_path_index_js-node_modules_d3-geo_src_projection_orthographic-ab9e2e.chunk.js and http://localhost:3000/static/js/src_globe_index_js.chunk.js files load.

```javascript
  import React, { Suspense } from 'react';

  const OtherComponent = React.lazy(() => import('./OtherComponent'));

  function MyComponent() {
    return (
      <div>
        <Suspense fallback={<div>Loading...</div>}>
          <OtherComponent />
        </Suspense>
      </div>
    );
  }
```

## webpackPrefetch: true comment
the webpackPrefetch: true comment, inside the import function, adds the javascript files to the document's
head tag. The browser will automatically load these files into the browser cache so they are ready ahead of time. It's a way to tell to the browser: "Hey, browser. As soon as you're all done loading everything, and when you're not busy doing stuff, then I want you to start prefetching some extra resources for me" and also says to the webpack: 
"Hey, Webpack. I want you to load all of the link tags that I need for loading this module." 

Example: when we use the webpackPrefetch comment for the globe exercise, it will load these both following files.
```javascript
<link rel="prefetch" as="script" href="/static/js/src_globe_index_js.chunk.js">
<link rel="prefetch" as="script" href="/static/js/vendors-node_modules_d3-geo_src_path_index_js-node_modules_d3-geo_src_projection_orthographic-ab9e2e.chunk.js">
```

## react suspense position
The react-suspense-boundary location has implications on the loading experience for your users and where that fallback UI falls in the React tree. I wouldn't necessarily recommend putting react-suspense-boundaries around every single component that could suspend. We probably want to locate that suspense-boundary closer to where it's relevant to provide a more useful fallback.

I would recommend being mindful about the type of fallback UI that you can provide to users based on the location of where that suspense-boundary appears, very similar to your Error boundaries.

If we want to test out our suspense-boundaries, we can go to the components DevTools, select any component down here, and click on the stopwatch. That will suspend that component, so we can see what suspense-boundary is going to handle it and what that fallback UI is going to look like.

## Coverage tool
When we apply this kind of optimizations, we need to compare the previous amount of code loaded before we have done this code-splitting. Basically, we have to compare the number of kilobytes of code loaded. We can find this information at the bottom of the coverage option inside the Network tab. For example, for the Globe exercise, we loaded 1.1 megabytes of code and once we implement this optimization method, we loaded 833 kilobytes. In the same way, what is relevant is that we loaded less code, and we ran less code in the final version. In the final version, we ran 189 kilobytes. Then in the exercise version, we ran 337 kilobytes. This code-splitting is helping to improve the speed at which our users are able to see and interact with our checkbox.

In the Usage Visualization column, inside the Coverage report, we can see that the graphs show in red the code that is not running in that moment and in blue the code that is running and it's necessary for the app in that moment as well. We can click on the file and it's gonna show the lines of code with the colors indicated previously.

## Background

Code splitting acts on the principle that loading less code will speed up your
app. Say for example that we're building a complex dashboard application that
includes the venerable d3 library for graphing data. Your users start
complaining because it takes too long to load the login screen.

So, considering that performance problems can be resolved by less code, how can we
solve this one? Well, do we really _need_ to have that code for the chart when
the user loads the login screen? Nope! We could load that on-demand.

Luckily for us, there's a built-in way to do this with JavaScript standards.
It's called a dynamic import and the syntax looks like this:

```javascript
import('/some-module.js').then(
  module => {
    // do stuff with the module's exports
  },
  error => {
    // there was some error loading the module...
  },
)
```

> üìú Learn more about dynamic imports in the browser in
> [Super Simple Start to ESModules in the browser](https://kentcdodds.com/blog/super-simple-start-to-es-modules-in-the-browser)

To take this further, React has built-in support for loading modules as React
components. The module must have a React component as the default export, and
you have to use the `<React.Suspense />` component to render a fallback value
while the user waits for the module to be loaded.

```javascript
// smiley-face.js
import * as React from 'react'

function SmileyFace() {
  return <div>üòÉ</div>
}

export default SmileyFace

// app.js
import * as React from 'react'

const SmileyFace = React.lazy(() => import('./smiley-face'))

function App() {
  return (
    <div>
      <React.Suspense fallback={<div>loading...</div>}>
        <SmileyFace />
      </React.Suspense>
    </div>
  )
}
```

ü¶â One great way to analyze your app to determine the need/benefit of code
splitting for a certain feature/page/interaction, is to use
[the "Coverage" feature of the developer tools](https://developer.chrome.com/docs/devtools/coverage).

## Exercise

Production deploys:

- [Exercise](https://react-performance.netlify.app/isolated/exercise/01.js)
- [Final](https://react-performance.netlify.app/isolated/final/01.js)

Our app has a neat Globe component that shows the user where they are on the
globe. Cool right? It's super duper fun.

But one day our product manager üë®‚Äçüíº came along and said that users are
complaining the app is taking too long to load. We're using several sizeable
libraries to have the really cool globe, but users only need to load it if they
click the "show globe" button and loading it ahead of time makes the app load
slower.

So your job as a performance professional is to load the code on-demand so the
user doesn't have to wait to see the checkbox.

For this one, you'll need to open the final in isolation and open the Chrome
DevTools Network tab to watch the webpack chunks load when you click "show
globe." Your objective is to have the network load those same chunks so they're
not in the bundle to begin with.

üí∞ Here's a quick tip: In the Network tab, there's a dropdown for artificially
throttling your network speed. It defaults to "Online" but you can change it to
"Fast 3G", "Slow 3G", etc.

Also, spend a bit of time playing with the coverage feature of the dev tools (as
noted above).

ü¶â You may also want to try running the production build so you can see what the
sizes are like post-minification: Run `npm run build` and then `npm run serve`.

ü¶â You may also want to use Incognito mode so your browser plugins don't mess
with the typical user experience.

## Extra Credit

### 1. üíØ eager loading

[Production deploy](https://react-performance.netlify.app/isolated/final/01.extra-1.js)

So it's great that the users can get the app loaded faster, but it's annoying
when 99% of the time the reason the users are using the app is so they can
interact with our globe. We don't want to have to make them wait first to load
the app and then again to load the globe. Wouldn't it be cool if we could have
globe start loading as soon as the user hovers over the checkbox? So if they
`mouseOver` or `focus` the `<label>` for the checkbox, we should kick off a
dynamic import for the globe module.

See if you can make that work.

> üí∞ Hint: it doesn't matter how many times you call
> `import('./path-to-module')`, webpack will only actually load the module once.

### 2. üíØ webpack magic comments

[Production deploy](https://react-performance.netlify.app/isolated/final/01.extra-2.js)

If you're using webpack to bundle your application, then you can use webpack
[magic comments](https://webpack.js.org/api/module-methods/#magic-comments) to
have webpack instruct the browser to prefetch dynamic imports:

```javascript
import(/* webpackPrefetch: true */ './some-module.js')
```

When webpack sees this comment, it adds this to your document's `head`:

```javascript
<link rel="prefetch" as="script" href="/static/js/1.chunk.js">
```

With this, the browser will automatically load this JavaScript file into the
browser cache so it's ready ahead of time.

The change itself is minimal, but pull up the DevTools to make sure it's loading
properly (you'll need to uncheck the "Disable cache" button to observe any
changes).

## Notes

Another thing which we won't cover in this workshop, but you should look into
later, is using the `webpackChunkName` magic comment which will allow webpack to
place common modules in the same chunk. This is good for components which you
want loaded together in the same chunk (to reduce multiple requests for multiple
modules which will likely be needed together).

You can play around with this in the `src/examples/code-splitting` directory.

## ü¶â Feedback

Fill out
[the feedback form](https://ws.kcd.im/?ws=React%20Performance%20%E2%9A%A1&e=01%3A%20Code%20splitting&em=).
